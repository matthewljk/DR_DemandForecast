{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month  Day  Period  Sum of Demand_Sum   Sum of DST  Sum of TCQ  \\\n",
      "0      2023   July    1       1               6120  5633.853332  486.146668   \n",
      "1      2023   July    1       2               6020  5554.891608  465.108392   \n",
      "2      2023   July    1       3               5911  5462.731620  448.268380   \n",
      "3      2023   July    1       4               5843  5408.646667  434.353333   \n",
      "4      2023   July    1       5               5798  5375.573341  422.426659   \n",
      "...     ...    ...  ...     ...                ...          ...         ...   \n",
      "12331  2024  March   13      44               6617  6094.329111  522.670889   \n",
      "12332  2024  March   13      45               6468  5975.891026  492.108974   \n",
      "12333  2024  March   13      46               6333  5844.349746  488.650254   \n",
      "12334  2024  March   13      47               6198  5762.694101  435.305899   \n",
      "12335  2024  March   13      48               6048  5653.727449  394.272551   \n",
      "\n",
      "            Actual  \n",
      "0      5633.853332  \n",
      "1      5554.891608  \n",
      "2      5462.731620  \n",
      "3      5408.646667  \n",
      "4      5375.573341  \n",
      "...            ...  \n",
      "12331  6094.329111  \n",
      "12332  5975.891026  \n",
      "12333  5844.349746  \n",
      "12334  5762.694101  \n",
      "12335  5653.727449  \n",
      "\n",
      "[12336 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/TCQ_DemandSum_DST.csv')\n",
    "df['Actual'] = df['Sum of DST']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert month names to numeric representation\n",
    "month_dict = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "df['Month'] = df['Month'].map(month_dict)\n",
    "\n",
    "# Combine year, month, day and period to form datetime\n",
    "df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day']]) + pd.to_timedelta((df['Period'] - 1) * 30, unit='minutes')\n",
    "\n",
    "# Set datetime column as the index\n",
    "df.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: (12331, 5, 1)\n",
      "Labels shape: (12331, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 5  # Define the length of each sequence\n",
    "\n",
    "# Extract \"Actual\" column to form single feature seqeunce\n",
    "demand_seq = df['Actual'].values\n",
    "\n",
    "# Scale the values\n",
    "scaler = StandardScaler()\n",
    "scaled_demand_seq = scaler.fit_transform(demand_seq.reshape(-1, 1))\n",
    "\n",
    "# Initialize lists to store input sequences and corresponding labels\n",
    "input_sequences = []\n",
    "labels = []\n",
    "\n",
    "# Create overlapping sequences of length sequence_length\n",
    "for i in range(len(scaled_demand_seq) - sequence_length):\n",
    "    # Extract a sequence of length sequence_length\n",
    "    sequence = scaled_demand_seq[i : i + sequence_length]\n",
    "    # Append the sequence to the input_sequences list\n",
    "    input_sequences.append(sequence)\n",
    "    # Append the next value (label) after the sequence to the labels list\n",
    "    labels.append(scaled_demand_seq[i + sequence_length])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the shapes of input_sequences and labels\n",
    "print(\"Input sequences shape:\", input_sequences.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into train and test sets. Set shuffle = False to preserve temporal order of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_sequences, labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "# For validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/Desktop/SDC_Demand_Forecast/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/Desktop/SDC_Demand_Forecast/venv/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6301 - loss: 0.4361 - val_RootMeanSquaredError: 0.1605 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.1574 - loss: 0.0248 - val_RootMeanSquaredError: 0.1309 - val_loss: 0.0172\n",
      "Epoch 3/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.1327 - loss: 0.0176 - val_RootMeanSquaredError: 0.1114 - val_loss: 0.0124\n",
      "Epoch 4/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.1128 - loss: 0.0127 - val_RootMeanSquaredError: 0.1043 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.1018 - loss: 0.0104 - val_RootMeanSquaredError: 0.0952 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.0927 - loss: 0.0086 - val_RootMeanSquaredError: 0.0930 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.0898 - loss: 0.0081 - val_RootMeanSquaredError: 0.0882 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.0847 - loss: 0.0072 - val_RootMeanSquaredError: 0.0919 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.0840 - loss: 0.0071 - val_RootMeanSquaredError: 0.0936 - val_loss: 0.0088\n",
      "Epoch 10/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.0837 - loss: 0.0070 - val_RootMeanSquaredError: 0.0927 - val_loss: 0.0086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2900b49d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the GRU model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=64, input_shape=(sequence_length, 1)),\n",
    "    tf.keras.layers.Dense(units=1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model with RMSE as the evaluation metric\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['RootMeanSquaredError'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.1051 - loss: 0.0111\n",
      "Test RMSE: 0.12274099141359329\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# Evaluate the model on test data\n",
    "loss, rmse = model.evaluate(X_test, y_test)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
