{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Net Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Get the values of host, user, pswd, db, and schema from the environment variables\n",
    "host = os.getenv('host')\n",
    "user = os.getenv('user')\n",
    "pswd = os.getenv('pswd')\n",
    "db = os.getenv('db')\n",
    "schema = os.getenv('schema')\n",
    "\n",
    "\n",
    "# Use the values as needed\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{user}:{pswd}@{host}/{db}?options=-csearch_path%3D{schema}\", echo=False)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from CSV to PostgreSQL\n",
    "\n",
    "This step is used for testing purposes.\n",
    "\n",
    "Set `IMPORT_DATA` to `False` to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "if IMPORT_DATA:\n",
    "    \n",
    "    # Load and filer data from csv file\n",
    "    \n",
    "    rt_dpr = pd.read_csv('./data/RT_DPR.csv')\n",
    "    rt_dpr = rt_dpr[['Date', 'Period', 'Demand', 'TCL', 'Transmission_Loss']]\n",
    "    rt_dpr['Transmission_Loss'] = rt_dpr['Transmission_Loss'].fillna(0)\n",
    "    rt_dpr = rt_dpr[rt_dpr['Date'] > '2023-06-30']\n",
    "    rt_dpr = rt_dpr.sort_values(by=['Date', 'Period'])\n",
    "    rt_dpr.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    vc_per = pd.read_csv('./data/VCData_Period.csv')\n",
    "    \n",
    "    # !!! The Real_Time_DPR table here is different from the one Matthew uses. Don't replace.\n",
    "    # rt_dpr.to_sql('Real_Time_DPR', conn, if_exists='replace', index=False)\n",
    "    vc_per.to_sql('VCData_Period', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is 2024-03-26 21:44 Period 44\n",
      "To predict: 2024-03-26 Period 45\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "now = dt.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d\")\n",
    "time = now.strftime(\"%H:%M\")\n",
    "\n",
    "period = int(now.strftime(\"%H\")) * 2 + int(now.strftime(\"%M\")) // 30 + 1\n",
    "\n",
    "\n",
    "if period + 1 > 48:\n",
    "    next_period = 1\n",
    "    next_date = now + dt.timedelta(days=1)\n",
    "    next_date = next_date.strftime(\"%Y-%m-%d\")\n",
    "else:\n",
    "    next_period = period + 1\n",
    "    next_date = date\n",
    "\n",
    "# next_date = '2024-03-25' # A hard-coded value for testing\n",
    "# next_period = 33 # A hard-coded value for testing\n",
    "print(f\"Now is {date} {time} Period {period}\")\n",
    "print(f\"To predict: {next_date} Period {next_period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Period</th>\n",
       "      <th>Demand</th>\n",
       "      <th>TCL</th>\n",
       "      <th>Transmission_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>45</td>\n",
       "      <td>6658.741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>44</td>\n",
       "      <td>7036.794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Period    Demand  TCL  Transmission_Loss\n",
       "0    2024-03-19      45  6658.741  0.0             34.758\n",
       "335  2024-03-26      44  7036.794  0.0             38.304"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_dpr = pd.read_sql(f\"\"\"\n",
    "                     SELECT \"Date\", \"Period\", \"Demand\", \"TCL\", \"Transmission_Loss\"\n",
    "\t                 FROM public.\"Real_Time_DPR\"\n",
    "                     WHERE (\"Date\" < '{date}' OR (\"Date\" = '{date}' AND \"Period\" < {next_period}))\n",
    "                     ORDER BY \"Date\" DESC, \"Period\" DESC  \n",
    "                     LIMIT 336\n",
    "                     \"\"\", conn)\n",
    "rt_dpr.sort_values(by=['Date', 'Period'], inplace=True)\n",
    "rt_dpr.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rt_dpr.iloc[[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Period</th>\n",
       "      <th>TCQ_Weekday</th>\n",
       "      <th>TCQ_Weekend_PH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>457184.607704</td>\n",
       "      <td>486146.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>437836.736105</td>\n",
       "      <td>448734.605604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Quarter  Period    TCQ_Weekday  TCQ_Weekend_PH\n",
       "0    2023        3       1  457184.607704   486146.668221\n",
       "191  2024        2      48  437836.736105   448734.605604"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_per = pd.read_sql('SELECT * FROM public.\"VCData_Period\"', conn)\n",
    "vc_per.iloc[[0, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "# Calculate required data fields\n",
    "\n",
    "sg_holidays = holidays.country_holidays('SG')\n",
    "\n",
    "rt_dpr['Total Demand'] = rt_dpr['Demand'] + rt_dpr['TCL'] + rt_dpr['Transmission_Loss']\n",
    "view = rt_dpr[['Date', 'Period', 'Total Demand']].copy()\n",
    "\n",
    "def find_tcq(row):\n",
    "    # print(row)\n",
    "    date_obj = dt.datetime.strptime(str(row['Date']), '%Y-%m-%d')\n",
    "    year = date_obj.year\n",
    "    quarter = (date_obj.month - 1) // 3 + 1\n",
    "    \n",
    "    period = row['Period']\n",
    "    \n",
    "    isWeekend = 1 if date_obj.isoweekday() > 5 else 0\n",
    "    isPublicHoliday = date_obj in sg_holidays\n",
    "    \n",
    "    if isWeekend or isPublicHoliday:\n",
    "        # print(f\"Date: {date_obj} isWeekend: {isWeekend} isPublicHoliday: {isPublicHoliday}\")\n",
    "        tcq = vc_per[(vc_per['Year'] == year) & (vc_per['Quarter'] == quarter) & (vc_per['Period'] == period)]['TCQ_Weekday'].values[0] / 1000\n",
    "    else:\n",
    "        tcq = vc_per[(vc_per['Year'] == year) & (vc_per['Quarter'] == quarter) & (vc_per['Period'] == period)]['TCQ_Weekend_PH'].values[0] / 1000\n",
    "\n",
    "    # print(f\"Date: {date_obj} TCQ: {tcq}\")\n",
    "    return tcq\n",
    "\n",
    "view['TCQ'] = view.apply(lambda row: find_tcq(row), axis=1)\n",
    "view['Net Demand'] = view['Total Demand'] - view['TCQ']\n",
    "view.reset_index(drop=True, inplace=True)\n",
    "# view.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/20240326_1239/'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load the most recent scaler file\n",
    "resDir = './model'\n",
    "newestDir = max(glob.glob(os.path.join(resDir, '*/')), key=os.path.getmtime)\n",
    "newestDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler files: ['./model/20240326_1239/robustScaler.pkl']\n",
      "Loaded scaler: ./model/20240326_1239/robustScaler.pkl\n",
      "Predict_X shape: (1, 336, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler_files = glob.glob(os.path.join(newestDir, \"*.pkl\"))\n",
    "print(\"Scaler files:\", scaler_files)\n",
    "scaler = joblib.load(scaler_files[0])\n",
    "print(\"Loaded scaler:\", scaler_files[0])\n",
    "\n",
    "# Transform data using the loaded scaler\n",
    "data = view.copy()\n",
    "data['Target'] = data['Net Demand']\n",
    "data['Target'] = scaler.fit_transform(data['Target'].values.reshape(-1,1))\n",
    "\n",
    "def create_dataset(dataset):\n",
    "    return np.array([dataset])\n",
    "\n",
    "predict_X = create_dataset(data['Target'].values)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "predict_X = np.reshape(predict_X, (predict_X.shape[0], predict_X.shape[1], 1))\n",
    "\n",
    "print(f\"Predict_X shape: {predict_X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.keras.utils.disable_interactive_logging()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: ./model/20240326_1239/bi-lstm.keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "# Get a list of all model files in the directory\n",
    "model_files = glob.glob(os.path.join(newestDir, \"*.keras\"))\n",
    "\n",
    "# Sort the list of model files by modification time (most recent first)\n",
    "model_files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "# Select the most recent model file\n",
    "most_recent_model_file = model_files[0]\n",
    "\n",
    "# Load the selected model\n",
    "model = load_model(most_recent_model_file)\n",
    "\n",
    "# Print the path of the loaded model for verification\n",
    "print(\"Loaded model:\", most_recent_model_file)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predict_result = model.predict(predict_X)\n",
    "\n",
    "# Invert predictions to original scale\n",
    "inverted_predictions = scaler.inverse_transform(predict_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 6440.05078125\n"
     ]
    }
   ],
   "source": [
    "# Print or use the predictions as needed\n",
    "print(f\"Predictions: {inverted_predictions[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Predicted_Net_Demand' exists: True\n",
      "Row exists: True\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Check if the table 'Predicted_Net_Demand' exists\n",
    "table_exists = engine.dialect.has_table(conn, 'Predicted_Net_Demand')\n",
    "print(f\"Table 'Predicted_Net_Demand' exists: {table_exists}\")\n",
    "if not table_exists:\n",
    "    # Create the table 'Predicted_Net_Demand'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE public.\"Predicted_Net_Demand\" (\n",
    "        \"Date\" DATE,\n",
    "        \"Period\" INTEGER,\n",
    "        \"Predicted_Net_Demand\" FLOAT,\n",
    "        PRIMARY KEY (\"Date\", \"Period\")\n",
    "    )\n",
    "    \"\"\"\n",
    "    conn.execute(text(create_table_query))\n",
    "\n",
    "# Check if a row with the same Date and Period exists\n",
    "row_exists_query = f\"\"\"\n",
    "SELECT EXISTS (\n",
    "    SELECT 1\n",
    "    FROM public.\"Predicted_Net_Demand\"\n",
    "    WHERE \"Date\" = '{next_date}' AND \"Period\" = '{next_period}'\n",
    ")\n",
    "\"\"\"\n",
    "row_exists = conn.execute(text(row_exists_query)).scalar()\n",
    "print(f\"Row exists: {row_exists}\")\n",
    "if row_exists:\n",
    "    # Update the existing row with the predicted net demand\n",
    "    update_query = f\"\"\"\n",
    "    UPDATE public.\"Predicted_Net_Demand\"\n",
    "    SET \"Predicted_Net_Demand\" = {inverted_predictions[0][0]}\n",
    "    WHERE \"Date\" = '{next_date}' AND \"Period\" = {next_period}\n",
    "    \"\"\"\n",
    "    conn.execute(text(update_query))\n",
    "else:\n",
    "    # Insert a new row with the predicted net demand\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO public.\"Predicted_Net_Demand\" (\"Date\", \"Period\", \"Predicted_Net_Demand\")\n",
    "    VALUES ('{next_date}', {next_period}, {inverted_predictions[0][0]})\n",
    "    \"\"\"\n",
    "    conn.execute(text(insert_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
